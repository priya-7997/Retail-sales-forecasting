{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb1fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting XGBoost Model Training...\n",
      "Dataset loaded: 1,017,209 records, 25 columns\n",
      "After feature engineering: 983,759 records\n",
      "Selected 19 features for training\n",
      "Training set: 787,007 samples\n",
      "Test set: 196,752 samples\n",
      "Training XGBoost model...\n",
      "\n",
      "==================================================\n",
      "    XGBOOST MODEL TRAINING COMPLETE\n",
      "==================================================\n",
      "ğŸ“Š Dataset Size: 983,759 records\n",
      "ğŸ¯ Features Used: 19\n",
      "ğŸ“ˆ Train RÂ²: 0.9677\n",
      "ğŸ“‰ Test RÂ²: 0.9635\n",
      "ğŸ’° Test RMSE: â‚¹735\n",
      "ğŸ“Š Test MAE: â‚¹471\n",
      "ğŸ“‹ Test MAPE: inf%\n",
      "==================================================\n",
      "âœ… Model saved to: ../models/xgb_model.pkl\n",
      "\n",
      "ğŸ” Top 5 Important Features:\n",
      "  1. IsWeekend: 0.3152\n",
      "  2. StateHoliday_Encoded: 0.2890\n",
      "  3. DayOfWeek: 0.1087\n",
      "  4. Sales_Mean_7: 0.0786\n",
      "  5. Promo: 0.0761\n",
      "\n",
      "ğŸ§ª Testing model loading...\n",
      "âœ… Model loading test successful!\n",
      "\n",
      "ğŸš€ Model ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "XGBoost Model for Retail Sales Forecasting\n",
    "Trains an XGBoost model and saves it as xgb_model.pkl\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create time-based and retail-specific features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle date column - check for different possible date column names\n",
    "    date_cols = ['Date', 'date', 'DATE']\n",
    "    date_col = None\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    if date_col:\n",
    "        df['Date'] = pd.to_datetime(df[date_col])\n",
    "        \n",
    "        # Time features\n",
    "        df['Year'] = df['Date'].dt.year\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "        df['Quarter'] = df['Date'].dt.quarter\n",
    "        df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "        \n",
    "        # Seasonal features\n",
    "        df['IsFestivalSeason'] = df['Month'].isin([10, 11, 12]).astype(int)\n",
    "        df['IsSummerSeason'] = df['Month'].isin([3, 4, 5]).astype(int)\n",
    "        \n",
    "        # Sort for lag features\n",
    "        if 'Store' in df.columns:\n",
    "            df = df.sort_values(['Store', 'Date'])\n",
    "            \n",
    "            # Lag features\n",
    "            for lag in [1, 7, 30]:\n",
    "                df[f'Sales_Lag_{lag}'] = df.groupby('Store')['Sales'].shift(lag)\n",
    "            \n",
    "            # Rolling statistics\n",
    "            for window in [7, 30]:\n",
    "                df[f'Sales_Mean_{window}'] = df.groupby('Store')['Sales'].rolling(window, min_periods=1).mean().reset_index(0, drop=True)\n",
    "        else:\n",
    "            # Simple lag features without store grouping\n",
    "            for lag in [1, 7, 30]:\n",
    "                df[f'Sales_Lag_{lag}'] = df['Sales'].shift(lag)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "def encode_categoricals(df):\n",
    "    \"\"\"Encode categorical variables\"\"\"\n",
    "    encoders = {}\n",
    "    categorical_cols = ['StoreType', 'Assortment', 'StateHoliday', 'SchoolHoliday']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_Encoded'] = le.fit_transform(df[col].astype(str))\n",
    "            encoders[col] = le\n",
    "    \n",
    "    return df, encoders\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸš€ Starting XGBoost Model Training...\")\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        df = pd.read_csv('../data/cleaned_data.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: cleaned_data.csv not found. Please ensure the data file exists.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Dataset loaded: {df.shape[0]:,} records, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Check for required columns\n",
    "    if 'Sales' not in df.columns:\n",
    "        print(\"Error: 'Sales' column not found in dataset\")\n",
    "        return\n",
    "    \n",
    "    # Feature engineering\n",
    "    df_featured = create_features(df)\n",
    "    print(f\"After feature engineering: {df_featured.shape[0]:,} records\")\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df_encoded, encoders = encode_categoricals(df_featured)\n",
    "    \n",
    "    # Select features for training\n",
    "    base_features = ['Month', 'DayOfWeek', 'Quarter', 'IsWeekend', 'IsFestivalSeason', 'IsSummerSeason']\n",
    "    \n",
    "    # Add lag and rolling features if they exist\n",
    "    lag_features = [col for col in df_encoded.columns if col.startswith(('Sales_Lag_', 'Sales_Mean_'))]\n",
    "    base_features.extend(lag_features)\n",
    "    \n",
    "    # Add other numerical features\n",
    "    optional_features = ['Store', 'Year', 'Promo', 'CompetitionDistance']\n",
    "    base_features.extend([col for col in optional_features if col in df_encoded.columns])\n",
    "    \n",
    "    # Add encoded categorical features\n",
    "    encoded_features = [col for col in df_encoded.columns if col.endswith('_Encoded')]\n",
    "    base_features.extend(encoded_features)\n",
    "    \n",
    "    # Filter to only available numeric features\n",
    "    available_features = []\n",
    "    for col in base_features:\n",
    "        if col in df_encoded.columns:\n",
    "            if df_encoded[col].dtype in ['int64', 'float64', 'bool', 'int32', 'float32']:\n",
    "                available_features.append(col)\n",
    "    \n",
    "    print(f\"Selected {len(available_features)} features for training\")\n",
    "    \n",
    "    # Prepare training data\n",
    "    X = df_encoded[available_features].fillna(0)\n",
    "    y = df_encoded['Sales']\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    print(\"Training XGBoost model...\")\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = xgb_model.predict(X_train)\n",
    "    y_pred_test = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    def calculate_metrics(y_true, y_pred):\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'mae': mean_absolute_error(y_true, y_pred),\n",
    "            'r2': r2_score(y_true, y_pred),\n",
    "            'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        }\n",
    "    \n",
    "    train_metrics = calculate_metrics(y_train, y_pred_train)\n",
    "    test_metrics = calculate_metrics(y_test, y_pred_test)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': xgb_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Create models directory\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # Save model (single file as requested)\n",
    "    model_path = '../models/xgb_model.pkl'\n",
    "    model_data = {\n",
    "        'model': xgb_model,\n",
    "        'features': available_features,\n",
    "        'encoders': encoders,\n",
    "        'metrics': {'train': train_metrics, 'test': test_metrics},\n",
    "        'feature_importance': feature_importance\n",
    "    }\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"    XGBOOST MODEL TRAINING COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"ğŸ“Š Dataset Size: {df_encoded.shape[0]:,} records\")\n",
    "    print(f\"ğŸ¯ Features Used: {len(available_features)}\")\n",
    "    print(f\"ğŸ“ˆ Train RÂ²: {train_metrics['r2']:.4f}\")\n",
    "    print(f\"ğŸ“‰ Test RÂ²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"ğŸ’° Test RMSE: â‚¹{test_metrics['rmse']:,.0f}\")\n",
    "    print(f\"ğŸ“Š Test MAE: â‚¹{test_metrics['mae']:,.0f}\")\n",
    "    print(f\"ğŸ“‹ Test MAPE: {test_metrics['mape']:.2f}%\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"âœ… Model saved to: {model_path}\")\n",
    "    print(\"\\nğŸ” Top 5 Important Features:\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "        print(f\"  {i}. {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Test model loading\n",
    "    print(\"\\nğŸ§ª Testing model loading...\")\n",
    "    with open(model_path, 'rb') as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    loaded_model = loaded_data['model']\n",
    "    test_pred = loaded_model.predict(X_test[:5])\n",
    "    original_pred = xgb_model.predict(X_test[:5])\n",
    "    \n",
    "    if np.allclose(test_pred, original_pred):\n",
    "        print(\"âœ… Model loading test successful!\")\n",
    "    else:\n",
    "        print(\"âŒ Model loading test failed!\")\n",
    "    \n",
    "    print(\"\\nğŸš€ Model ready for deployment!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
